# -*- coding: utf-8 -*-
"""Monica_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RTxLG0DYMlx2FtnvOZjJnE8NRQt6fXki
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Ignore warnings
import warnings
warnings.filterwarnings("ignore")

# Core libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
from tabulate import tabulate
import math

# Preprocessing and modeling
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score
from sklearn.metrics import (
    accuracy_score, balanced_accuracy_score, precision_score,
    recall_score, f1_score, roc_auc_score, confusion_matrix
)

# Classifiers
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB

# Oversampling
from imblearn.over_sampling import SMOTE

# SHAP
import shap

directory = "/content/drive/MyDrive/Microfinance/"
application_train = pd.read_csv(directory + 'application_train.csv')
bureau = pd.read_csv(directory + 'bureau.csv')
bureau_balance = pd.read_csv(directory + 'bureau_balance.csv')
previous_application = pd.read_csv(directory + 'previous_application.csv')
pos_cash = pd.read_csv(directory + 'POS_CASH_balance.csv')
installments_payments = pd.read_csv(directory + 'installments_payments.csv')
credit_card_balance = pd.read_csv(directory + 'credit_card_balance.csv')

application_train

bureau

bureau_balance

pos_cash

previous_application

installments_payments

credit_card_balance

print("== application_train ==")
application_train.info()
print("\n== bureau ==")
bureau.info()
print("\n== bureau_balance ==")
bureau_balance.info()
print("\n== previous_application ==")
previous_application.info()
print("\n== POS_CASH_balance ==")
pos_cash.info()
print("\n== installments_payments ==")
installments_payments.info()
print("\n== credit_card_balance ==")
credit_card_balance.info()

def di(df, name):
    print(f"== {name} ==")
    print(df.info())
    print(f"\nShape: {df.shape}")
    print("\nData Types:\n", df.dtypes.value_counts())
    print("\nMissing Values:\n", df.isnull().sum()[df.isnull().sum() > 0])
    if 'TARGET' in df.columns:
        print("\nTARGET Value Counts:\n", df['TARGET'].value_counts())
        print("\nTARGET Class Distribution (%):\n", df['TARGET'].value_counts(normalize=True) * 100)
    print("="*80)

di(application_train, "application_train")
di(bureau, "bureau")
di(bureau_balance, "bureau_balance")
di(previous_application, "previous_application")
di(pos_cash, "POS_CASH_balance")
di(installments_payments, "installments_payments")
di(credit_card_balance, "credit_card_balance")

"""    1.** application_train**
Rows: 9692 | Cols: 122
Target Distribution:
  0 (no default): 92.21%
  1 (default): 7.79% → imbalanced data
Missing values: Present in 107 columns. Some with 1300+ missing.
Types: Mostly float64 and object.

    2. **bureau**
Rows: 53123 | Cols: 17
Key Columns: SK_ID_CURR, SK_ID_BUREAU
Missing values: Many columns, notably AMT_ANNUITY (78% missing), AMT_CREDIT_MAX_OVERDUE, etc.

    3. **bureau_balance**
Rows: 305,164 | Cols: 3
Key Columns: SK_ID_BUREAU → links with bureau
Minimal missing: Only 1 missing row.

    4. **previous_application**
Rows: 548,205 | Cols: 37
Key Columns: SK_ID_CURR, SK_ID_PREV
Heavy missing: RATE_INTEREST_*, DAYS_*, AMT_* have significant nulls.

    5. **POS_CASH_balance**
Rows: 1,920,985 | Cols: 8
Key Columns: SK_ID_CURR, SK_ID_PREV
Minimal missing: 3550 rows for installment features.

    6. **installments_payments**
Rows: 59,185 | Cols: 8
Key Columns: SK_ID_CURR, SK_ID_PREV
Minimal missing: Only 1 row missing.

    7. **credit_card_balance**
Rows: 2,509,622 | Cols: 23
Key Columns: SK_ID_CURR, SK_ID_PREV
Minimal missing overall.
"""

def fun():
    warnings.warn("deprecated", DeprecationWarning)

with warnings.catch_warnings():
    warnings.simplefilter("ignore")
    fun()

def showdata(name, df):
    print(name, "Shape:", df.shape)
    print(df.head())
    print(df.describe(include='all'))
    plt.figure(figsize=(6, 4))
    sns.heatmap(df.isnull().mean().to_frame().T, cmap='coolwarm', cbar_kws={'label': 'Missing'})
    plt.title('Missing in ' + name)
    plt.show()

def loaddata():
    app = pd.read_csv(directory + 'application_train.csv')
    bur = pd.read_csv(directory + 'bureau.csv')
    burbal = pd.read_csv(directory + 'bureau_balance.csv')
    prev = pd.read_csv(directory + 'previous_application.csv')
    pos = pd.read_csv(directory + 'POS_CASH_balance.csv')
    inst = pd.read_csv(directory + 'installments_payments.csv')
    card = pd.read_csv(directory + 'credit_card_balance.csv')

    showdata("app", app)
    showdata("bur", bur)
    showdata("burbal", burbal)
    showdata("prev", prev)
    showdata("pos", pos)
    showdata("inst", inst)
    showdata("card", card)

    numcol = burbal.select_dtypes(include=['number']).columns
    burbalagg = burbal.groupby('SK_ID_BUREAU')[numcol].mean()
    burbalagg = burbalagg.rename(columns=lambda x: "BB_" + x)

    bur = bur.merge(burbalagg, how='left', on='SK_ID_BUREAU')
    bur = bur.drop(columns=['SK_ID_BUREAU'], errors='ignore')

    prev = prev.drop_duplicates(subset=['SK_ID_PREV'])
    pos = pos.drop_duplicates(subset=['SK_ID_PREV'])
    inst = inst.drop_duplicates(subset=['SK_ID_PREV'])
    card = card.drop_duplicates(subset=['SK_ID_PREV'])

    prev = prev.merge(pos, on='SK_ID_PREV', how='left', suffixes=('_prev', '_pos'))
    prev = prev.merge(inst, on='SK_ID_PREV', how='left', suffixes=('', '_inst'))
    prev = prev.merge(card, on='SK_ID_PREV', how='left', suffixes=('', '_card'))

    if 'SK_ID_CURR_x' in prev.columns and 'SK_ID_CURR_y' in prev.columns:
        prev = prev.rename(columns={'SK_ID_CURR_x': 'SK_ID_CURR'})
        prev = prev.drop(columns=['SK_ID_CURR_y'])

    data = app.merge(bur, on='SK_ID_CURR', how='left')
    data = data.merge(prev, on='SK_ID_CURR', how='left')

    return data

data = loaddata()

data

#categorical features
categorical_features = data.select_dtypes(include=['object', 'category']).columns.tolist()
print("Categorical features:", categorical_features)
n = len(categorical_features)
n_cols = 2
n_rows = math.ceil(n / n_cols)

plt.figure(figsize=(6 * n_cols, 5 * n_rows))
sns.set(style="whitegrid")

for i, col in enumerate(categorical_features, 1):
    plt.subplot(n_rows, n_cols, i)
    value_counts = data[col].value_counts().sort_values(ascending=False)
    sns.barplot(x=value_counts.index, y=value_counts.values, palette='viridis')
    plt.title(col)
    plt.ylabel('Count')
    plt.xlabel('Category')
    plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

numerical_features = data.select_dtypes(include=['number']).columns.tolist()

n_cols = 2
n_rows = math.ceil(len(numerical_features) / n_cols)

plt.figure(figsize=(6 * n_cols, 5 * n_rows))
sns.set(style="whitegrid")

for i, col in enumerate(numerical_features, 1):
    plt.subplot(n_rows, n_cols, i)
    sns.histplot(data[col].dropna(), kde=True, color='skyblue')
    plt.title(f'{col} (Numerical)')
    plt.xlabel('Value')
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

numeric_features = data.select_dtypes(include=['int64', 'float64']).columns
n_cols = 4
n_rows = math.ceil(len(numeric_features) / n_cols)

plt.figure(figsize=(5 * n_cols, 4 * n_rows))
sns.set(style="whitegrid")

for i, col in enumerate(numeric_features, 1):
    plt.subplot(n_rows, n_cols, i)
    sns.boxplot(y=data[col], color='skyblue')
    plt.title(col, fontsize=10)
    plt.xlabel('')
    plt.tight_layout()

plt.suptitle("Numeric Features Boxplot", fontsize=16, y=1.02)
plt.show()

numeric_cols = data.select_dtypes(include=['int64', 'float64'])
skewness_values = numeric_cols.skew().sort_values()
skew_df = pd.DataFrame({'Feature': skewness_values.index, 'Skewness': skewness_values.values})
plt.figure(figsize=(25, 34))
sns.set(style="whitegrid")

sns.barplot(x='Skewness', y='Feature', data=skew_df, palette='viridis')
plt.title('Numeric Features Skewness', fontsize=16)
plt.xlabel('Skewness')
plt.ylabel('Numeric Features')
plt.tight_layout()
plt.show()

missing_counts = data.isnull().sum()

missing_counts = missing_counts[missing_counts > 0]

plt.figure(figsize=(20, 10))  # Bigger figure size
sns.barplot(x=missing_counts.index, y=missing_counts.values, palette='coolwarm')

plt.title('Missing Values Count per Column', fontsize=16)
plt.xlabel('Columns', fontsize=14)
plt.ylabel('Number of Missing Values', fontsize=14)

plt.xticks(rotation=90, fontsize=6)  # Rotate labels and reduce font size for readability
plt.yticks(fontsize=0.5)

plt.tight_layout()
plt.show()

mf = data.isnull().sum() / len(data)
threshold = 0.2


droplist = mf[mf > threshold].index
data = data.drop(columns=droplist)

numcols = data.select_dtypes(include=['number']).columns.tolist()
catcols = data.select_dtypes(include=['object']).columns.tolist()

mi = SimpleImputer(strategy='median')
data[numcols] = mi.fit_transform(data[numcols])

fi = SimpleImputer(strategy='most_frequent')
data[catcols] = fi.fit_transform(data[catcols])

#ler
encoder = LabelEncoder()
for col in catcols:
    data[col] = encoder.fit_transform(data[col].astype(str))

data['CODE_GENDER']

missing_counts = data.isnull().sum()

missing_counts = missing_counts[missing_counts > 0]

plt.figure(figsize=(4, 6))  # figure size
sns.barplot(x=missing_counts.index, y=missing_counts.values, palette='coolwarm')

plt.title('After cleaning  a column -Missing Values Count per Column', fontsize=16)
plt.xlabel('Columns', fontsize=14)
plt.ylabel('Number of Missing Values', fontsize=14)

plt.xticks(rotation=90, fontsize=6)  # Rotate labels and reduce font size for readability
plt.yticks(fontsize=0.5)

plt.tight_layout()
plt.show()#No

#after encoding
data

X = data.drop(columns=['TARGET', 'SK_ID_CURR'])
y = data['TARGET']

data

sc = StandardScaler()
Xnew = sc.fit_transform(X)

plt.figure(figsize=(6, 4))
sns.countplot(x=y, palette="Set2")
plt.title("Class Before SMOTE")
plt.xlabel("Target")
plt.ylabel("Count")
plt.show()

sm = SMOTE(random_state=42)
Xbal, ybal = sm.fit_resample(Xnew, y)

ts = TSNE(n_components=2, perplexity=30, random_state=42)
Xtsne = ts.fit_transform(Xnew)

plt.figure(figsize=(8, 6))
sns.scatterplot(x=Xtsne[:,0], y=Xtsne[:,1], hue=y, palette="coolwarm", legend='full')
plt.title('t-SNE After Scaling')
plt.xlabel('t-SNE 1')
plt.ylabel('t-SNE 2')
plt.show()

plt.figure(figsize=(6, 4))
sns.countplot(x=ybal, palette="Set1")
plt.title("Class After SMOTE")
plt.xlabel("Target")
plt.ylabel("Count")
plt.show()

data.info()

if 'TARGET' in data.columns:
    c = data.corr()
    t = c['TARGET'].drop('TARGET').abs().sort_values(ascending=False).head(20).index.tolist()
    t.append('TARGET')

    plt.figure(figsize=(15, 10))
    sns.heatmap(data[t].corr(), annot=True, cmap='coolwarm')
    plt.title('Top Correlation')
    plt.show()

#Total input/output(Target) features
variable_table = pd.DataFrame({
    'Variable Name': data.columns,
    'Data Type': [data[col].dtype for col in data.columns]
})
variable_table.reset_index(drop=True, inplace=True)
print(tabulate(variable_table, headers='keys', tablefmt='grid', showindex=False))

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV
from sklearn.metrics import (accuracy_score, balanced_accuracy_score, precision_score, recall_score,
                             f1_score, roc_auc_score, confusion_matrix)
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier
from collections import defaultdict

# Define parameter grids
param_grid_xgb = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.05], 'max_depth': [3, 5]}
param_grid_knn = {'n_neighbors': [3, 5, 7]}
param_grid_dt = {'max_depth': [3, 5, 10], 'min_samples_split': [2, 5, 10]}

# Results containers
all_results = []
af1 = {"XGBoost": [], "KNN": [], "DecisionTree": [], "NaiveBayes": []}
conf_matrices = defaultdict(list)

# Training loop for 10 runs
for run_seed in range(10):
    print(f"\nRun {run_seed + 1} with random_state = {run_seed}")

    inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=run_seed)
    outer_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=run_seed)

    xgb = RandomizedSearchCV(
        XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss', random_state=run_seed),
        param_grid_xgb, n_iter=5, cv=inner_cv, scoring='f1', random_state=run_seed
    )
    knn = RandomizedSearchCV(
        KNeighborsClassifier(),
        param_grid_knn, n_iter=5, cv=inner_cv, scoring='f1', random_state=run_seed
    )
    dt = RandomizedSearchCV(
        DecisionTreeClassifier(random_state=run_seed),
        param_grid_dt, n_iter=5, cv=inner_cv, scoring='f1', random_state=run_seed
    )
    nb = GaussianNB()

    models = {"XGBoost": xgb, "KNN": knn, "DecisionTree": dt, "NaiveBayes": nb}

    if isinstance(Xbal, np.ndarray):
        Xbal = pd.DataFrame(Xbal, columns=X.columns)
    if isinstance(ybal, np.ndarray):
        ybal = pd.Series(ybal)

    # Add gender column
    Xbal['Gender'] = X['CODE_GENDER']
    Xtrain, Xtest, Ytrain, Ytest = train_test_split(Xbal, ybal, test_size=0.2, random_state=run_seed)

    gender_male_indices = Xtest[Xtest['Gender'] == 1].index
    gender_female_indices = Xtest[Xtest['Gender'] == 0].index

    results = {}

    for name, model in models.items():
        print(f"  Training {name}...")

        model.fit(Xtrain.drop(columns=['Gender']), Ytrain)

        Xtest_nogender = Xtest.drop(columns=['Gender']) if 'Gender' in Xtest.columns else Xtest
        Ypred = model.predict(Xtest_nogender)
        Yprob = model.predict_proba(Xtest_nogender)[:, 1] if hasattr(model, "predict_proba") else np.zeros(len(Ypred))

        nested_scores = cross_val_score(model, Xbal.drop(columns=['Gender']), ybal, cv=outer_cv, scoring='f1')
        af1[name].extend(nested_scores)

        Ypred_series = pd.Series(Ypred, index=Xtest.index)
        Ytest_series = pd.Series(Ytest.values, index=Xtest.index)
        f1_male = f1_score(Ytest_series.loc[gender_male_indices], Ypred_series.loc[gender_male_indices])
        f1_female = f1_score(Ytest_series.loc[gender_female_indices], Ypred_series.loc[gender_female_indices])
        cm = confusion_matrix(Ytest, Ypred)
        conf_matrices[name].append(cm)

        # Store metrics
        results[name] = {
            "MFS": nested_scores.mean(),
            "Standard_Error": nested_scores.std() / np.sqrt(len(nested_scores)),
            "Accuracy": accuracy_score(Ytest, Ypred),
            "BalancedAccuracy": balanced_accuracy_score(Ytest, Ypred),
            "Precision": precision_score(Ytest, Ypred),
            "Recall": recall_score(Ytest, Ypred),
            "F1Score": f1_score(Ytest, Ypred),
            "AUCROC": roc_auc_score(Ytest, Yprob),
            "F1Score_Male": f1_male,
            "F1Score_Female": f1_female
        }

    all_results.append(results)

# Build final result DataFrame
final_results = []
for run_result in all_results:
    for model_name, metrics in run_result.items():
        final_results.append({
            "Model": model_name,
            "MFS": metrics["MFS"],
            "Standard_Error": metrics["Standard_Error"],
            "Accuracy": metrics["Accuracy"],
            "BalancedAccuracy": metrics["BalancedAccuracy"],
            "Precision": metrics["Precision"],
            "Recall": metrics["Recall"],
            "F1Score": metrics["F1Score"],
            "AUCROC": metrics["AUCROC"],
            "F1Score_Male": metrics["F1Score_Male"],
            "F1Score_Female": metrics["F1Score_Female"]
        })

final_df = pd.DataFrame(final_results)

# Build combined plot data for F1 and AUCROC
comparison_plot_data = []
for run_idx, run_result in enumerate(all_results, start=1):
    for model_name, metrics in run_result.items():
        comparison_plot_data.append({
            "Run": run_idx,
            "Model": model_name,
            "Metric": "F1 Score",
            "Score": metrics["F1Score"]
        })
        comparison_plot_data.append({
            "Run": run_idx,
            "Model": model_name,
            "Metric": "AUC-ROC",
            "Score": metrics["AUCROC"]
        })

comparison_df = pd.DataFrame(comparison_plot_data)


sns.set(style="whitegrid")
g = sns.catplot(
    data=comparison_df,
    x="Run", y="Score", hue="Model",
    col="Metric", kind="bar", palette="Set2",
    height=6, aspect=1.2, ci=None
)

g.set_titles("{col_name}")
g.set_axis_labels("Run", "Score")
g.set(ylim=(0, 1))
g.fig.subplots_adjust(top=0.85)
g.fig.suptitle("F1 Score and AUC-ROC Across 10 Runs by Model", fontsize=16, weight='bold')
plt.tight_layout()
plt.show()


auroc_df = comparison_df[comparison_df['Metric'] == 'AUC-ROC']

plt.figure(figsize=(10, 6))
sns.lineplot(data=auroc_df, x="Run", y="Score", hue="Model", marker="o", palette="Set1")
plt.title("AUC-ROC Score Across 10 Runs by Model", fontsize=16, weight='bold')
plt.xlabel("Run")
plt.ylabel("AUC-ROC Score")
plt.ylim(0, 1)
plt.grid(True)
plt.tight_layout()
plt.show()

a=0
b=3
for i in range(10):
    print(f"\nRun {i + 1} with random_state = {i}")
    print(final_df.iloc[a:b+1:])
    a=a+4
    b=b+4

nested_f1_plot_df = pd.DataFrame([
    {"Model": model, "F1_Score": score}
    for model, scores in af1.items()
    for score in scores
])

# Summary statistics
ss = nested_f1_plot_df.groupby("Model")["F1_Score"].agg(['mean', 'std', 'count']).reset_index()

# Box plot
plt.figure(figsize=(8, 6))
sns.boxplot(data=nested_f1_plot_df, x="Model", y="F1_Score", palette="Set2")
plt.title("Nested F1 Score Distribution per Model")
plt.ylabel("F1 Score")
plt.xlabel("Model")
plt.ylim(0.6, 1)
plt.tight_layout()
plt.show()

summary = final_df.groupby("Model")[["MFS", "F1Score_Male", "F1Score_Female"]].mean().round(3)
print(summary)

plt.figure(figsize=(10, 6))
gender_plot_data = final_df.groupby("Model")[["F1Score_Male", "F1Score_Female"]].mean().reset_index()

gender_plot_data.plot(x="Model", kind="bar", figsize=(10, 6),
                      y=["F1Score_Male", "F1Score_Female"],
                      color=["blue", "pink"])

plt.title("Average F1 Score by Gender for Each Model")
plt.ylabel("F1 Score")
plt.xlabel("Model")
plt.xticks(rotation=0)
plt.ylim(0, 1)
plt.legend(title="Gender")
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()

plt.savefig("gender_f1score_comparison.png")
plt.show()

#shap for XG boost
bx = xgb.best_estimator_

Xtest_df = pd.DataFrame(Xtest, columns=X.columns)

Xsample = Xtest_df.sample(n=100, random_state=42) if len(Xtest_df) > 100 else Xtest_df.copy()

explainer = shap.TreeExplainer(bx)

shap_values = explainer.shap_values(Xsample)

sd = pd.DataFrame(shap_values, columns=Xsample.columns)

ms = np.abs(sd).mean().sort_values(ascending=False)

print("Top 20 SHAP values:")
print(ms.head(20))

top_features = ms.head(20).index.tolist()
xs = Xsample[top_features]
sv = sd[top_features].values

# SHAP plots
shap.summary_plot(sv, xs, plot_type="bar", plot_size=(10, 6))
shap.summary_plot(sv, xs)

fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes = axes.flatten()

for i, (model_name, matrices) in enumerate(conf_matrices.items()):
    avg_cm = np.mean(matrices, axis=0)

    sns.heatmap(avg_cm, annot=True, fmt='.2f', cmap='Blues', ax=axes[i])
    axes[i].set_title(f"Average Confusion Matrix: {model_name}")
    axes[i].set_xlabel("Predicted Label")
    axes[i].set_ylabel("True Label")

plt.tight_layout()
plt.show()